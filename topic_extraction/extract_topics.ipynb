{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get extractions from the wikifier API\n",
    "\n",
    "params\n",
    "------------------------\n",
    "extraction_string (str)- input string to extract\n",
    "                            DBPedia entities from within\n",
    "page_rank_sq_threshold (float)\n",
    "    \"set this to a real number x to calculate a threshold for pruning the annotations on\n",
    "    the basis of their pagerank score. The Wikifier will compute the sum of squares of all\n",
    "    the annotations (e.g. S), sort the annotations by decreasing order of pagerank, and calculate a\n",
    "    threshold such that keeping the annotations whose pagerank exceeds this threshold would bring\n",
    "    the sum of their pagerank squares to S · x. Thus, a lower x results in a higher threshold and\n",
    "    less annotations. (Default value: −1, which disables this mechanism.) The resulting threshold\n",
    "    is reported in the minPageRank field of the JSON result object. If you want the Wikifier to\n",
    "    actually discard the annotations whose pagerank is < minPageRank instead of including them in\n",
    "    the JSON result object, set the applyPageRankSqThreshold parameter to true (its default value is false).\"\n",
    "\n",
    "apply_page_rank_sq_threshold (bool) -\n",
    "    If you want the Wikifier to actually discard the annotations whose pagerank is < minPageRank\n",
    "    instead of including them in the JSON result object, set the applyPageRankSqThreshold\n",
    "    parameter to true (its default value is false).\n",
    "\n",
    "min_link_freq (int) -\n",
    "    if a link with a particular combination of anchor text and\n",
    "    target occurs in very few Wikipedia pages (less than the value of minLinkFrequency),\n",
    "    this link is completely ignored and the target page is not considered as a candidate\n",
    "    annotation for the phrase that matches the anchor text of this link.\n",
    "    (Default value: 1, which effectively disables this heuristic.)\n",
    "\n",
    "max_mention_entropy (float) -\n",
    "    set this to a real number x to cause all highly ambiguous mentions to be ignored\n",
    "    (i.e. they will contribute no candidate annotations into the process).\n",
    "    The heuristic used is to ignore mentions where H(link target | anchor text = this mention) > x.\n",
    "    (Default value: −1, which disables this heuristic.)\n",
    "\n",
    "max_targets_per_mention (int) -\n",
    "    set this to an integer x to use only the most frequent x candidate annotations\n",
    "    for each mention (default value: 20). Note that some mentions appear as the\n",
    "    anchor text of links to many different pages in the Wikipedia, so disabling this\n",
    "    heuristic (by setting x = −1) can increase the number of candidate annotations\n",
    "    significantly and make the annotation process slower.\n",
    "\n",
    "wikiDataClasses (bool) -\n",
    "    determines whether to include, for each annotation, a list if wikidata\n",
    "    (concept ID, concept name) pairs for all classes to which concept belongs directly or indirectly.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
